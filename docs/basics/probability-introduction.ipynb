{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "In this notebook, you will:\n",
    "\n",
    "- Learn how to define foundational terminology for reasoning about probability, distributions, and likelihoods.\n",
    "- Use probability distributions implemented in the `scipy.stats` library to understand those terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So, what is... probability?\n",
    "\n",
    "As a learner of Bayesian statistics, \n",
    "you, ahem, _probably_ (\\*cough cough\\*) have heard of the term \"probability\".\n",
    "What exactly is this beast?\n",
    "How do I learn it without getting lost in an entanglement of unclear terminology?\n",
    "\n",
    "Getting down to its core, using relatable and understandable words and pictures,\n",
    "is what I want to do in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spaces\n",
    "\n",
    "Firstly, probability is concerned with _spaces of possibilities_,\n",
    "and outcomes drawn from these spaces of possibilities\n",
    "that are non-deterministic.\n",
    "(In classical statistics, this \"space\" of possibilities\n",
    "is also called a \"support\".)\n",
    "\n",
    "To illustrate this point, here's a few examples.\n",
    "\n",
    "### Coin flips\n",
    "\n",
    "With the classic coin flip, the complete space of possibilities are the heads and tails.\n",
    "Under the most common circumstances, landing on neither heads nor tails\n",
    "is considered out of the space of possibilities.\n",
    "\n",
    "### Rolling dice\n",
    "\n",
    "With dice rolling, the complete space of possibilities that we are interested in\n",
    "are each of the sides.\n",
    "On a six-sided dice, the space of possibilities are the sides 1-6 inclusive.\n",
    "The side with the number 7... doesn't exist.\n",
    "And as such, it's outside of the space of possibilities.\n",
    "\n",
    "### Counts of stuff\n",
    "\n",
    "When we count things, the space of possibilities is the set of all positive integers,\n",
    "including the number 0.\n",
    "For example, when counting the number of car crashes at an intersection,\n",
    "-1 car accidents is quite commonly left out of the realm of possibilities.\n",
    "\n",
    "### Heights of adult people\n",
    "\n",
    "When measured in meters, the space of possibilities is the set of all positive real numbers.\n",
    "Strictly speaking, we might bound the space of possibilities even further,\n",
    "though for convenience, we often choose not to.\n",
    "(Though biologically highly implausible and improbable,\n",
    "a 0.1m tall adult human is _technically_ within the space of all positive real numbers.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events and Outcomes\n",
    "\n",
    "With probability, we are also concerned with \"events\".\n",
    "A coin flip, a dice roll, and a car entering an intersection are \"events\",\n",
    "and events are when our observed data are generated.\n",
    "\n",
    "At each _event_, there is an _outcome_ that is drawn from the space of possibilities.\n",
    "\n",
    "For example, when a dice roll _event_ takes place,\n",
    "any one of the six sides is a possible _outcome_.\n",
    "\n",
    "As another example, when a counting the number of car crashes at an intersection per day,\n",
    "each day is an _event_,\n",
    "and the number of car crashes happening in that day \n",
    "is the _outcome_ drawn from the positive integers space.\n",
    "\n",
    "Finally, when a human is born and finally grown up,\n",
    "them growing up is an event (in both the metaphorical and real sense!),\n",
    "and their adult height at a given point in time\n",
    "is the _outcome_drawn from the positive real numbers space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability as \"Credibility Points\"\n",
    "\n",
    "Probability is also concerned with credibility points assigned to each of the possible outcomes.\n",
    "\n",
    "The easiest way to think about these credibility points is to think of it in terms of an \"area\".\n",
    "Give yourself a two-dimensional blob, with 1 unit of area.\n",
    "What you're doing with probability is assigning fractions of this area\n",
    "to each of the _outcomes_.\n",
    "\n",
    "Here, the _only_ requirements to how area is assigned to each of the outcomes:\n",
    "\n",
    "- It must be positive.\n",
    "- The total area assigned to all possible outcomes must sum to 1.\n",
    "\n",
    "Let's look at a few examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete \"Credibility Points\"\n",
    "\n",
    "For a coin flip, if you have a fair coin,\n",
    "you might assign 0.5 of the area to one outcome, and 0.5 of the area to the other.\n",
    "Or if you have a biased coin, you would assign $p$ to one outcome and $1-p$ to the other.\n",
    "\n",
    "If you have a six-sided dice,\n",
    "you might assign $\\frac{1}{6}$ of the area to each of the outcomes,\n",
    "if the dice were fair.\n",
    "\n",
    "If you have a 100-sided dice,\n",
    "you might assign $\\frac{1}{100}$ of the area to each of the outcomes.\n",
    "\n",
    "There is a function that assigns area to each outcome.\n",
    "It's a bit like assigning a lump of mass to each outcome.\n",
    "The function that we get to define, or that others may have defined for us,\n",
    "is called the **probability mass function**.\n",
    "\n",
    "What's cool is that if we straighten out one side of that area\n",
    "such that it is of length 1 unit,\n",
    "then now the height value is equal to the area value.\n",
    "Keep this in mind; the _height_ is going to come in pretty handy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous \"Credibility Points\"\n",
    "\n",
    "When we think about assignment of credibility points to a continuous outcome space,\n",
    "we must remember that the area we assign to each of the outcomes must sum to 1.\n",
    "\n",
    "Let's consider the interval $[0, 1]$.\n",
    "How many _real_ numbers lie in that interval? \n",
    "\n",
    "_It's actually infinite..._\n",
    "\n",
    "As such, unlike the discrete case, if we try to assign any real area to a signle number,\n",
    "within the constrained bound of $[0, 1]$, we would end up with infinite area!\n",
    "\n",
    "So instead of assigning area to individual values, we assign area to a range of values,\n",
    "with increasing or decreasing _density_ of area per unit interval,\n",
    "taken _in the limit as the interval width approaches 0_.\n",
    "That curve we draw, which tells us the density of area over an infinitesimal interval,\n",
    "is called the **probability density function** (PDF).\n",
    "\n",
    "The corollary of this definition is that there is 0 probability associated with any value;\n",
    "probability can only be associated with a _range_ of values.\n",
    "That is because there is 0 area associated with any value under the PDF.\n",
    "\n",
    "That said, even though there is no _area_ associated with a single value,\n",
    "there is still _height_ associated with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules of Probability and Likelihood\n",
    "\n",
    "The rules of probability and likelihood give us the basic tools to work with data.\n",
    "The unfortunate piece is that terminology gets mixed up so frequently,\n",
    "we end up with a muddied understanding of how to calculate with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coin Flips\n",
    "\n",
    "Let's start simple, and look at the rules in the context of coin flips.\n",
    "\n",
    "When we flip a fair coin once and we get a heads (denote this with `H`), what is the _likelihood_ (height) of this event happening? It should be trivial to grasp: 0.5.\n",
    "Let's denote this as $\\mathcal{L}(\\text{H})$.\n",
    "\n",
    "When we flip a fair coin twice and obtain the outcome `HT` (a head, followed by a tail), what is the _joint likelihood_ of these two events happening in this sequence? By the rules of probability and likelihood, we multiply the _likelihoods_ of each individual _outcome_ together. Let's denote this $\\mathcal{L}(\\text{HT})$, and is equal to $0.5 \\times 0.5 = 0.25$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two pointers: Multiplication, and Likelihoods\n",
    "\n",
    "At this point, we need to disentangle a few ideas.\n",
    "\n",
    "Firstly, where does the multiplication of likelihoods come from? It comes from considering all of the possible spaces induced by the _joint space of outcomes_. If I have two possible outcomes for the first event and two possible outcomes for the second event, then in total I have 4 possible joint outcomes (`HT`, `HH`, `TH`, `TT`). Those of us who have received at least basic high school math training should know that the multiplication of likelihoods gives us the correct answer.\n",
    "\n",
    "But wait, why do I keep saying \"multiplication of likelihoods\" rather than \"multiplication of probabilities\"? \n",
    "This comes to the second distinction, between likelihood and probability:\n",
    "\n",
    "- Probability (the _area_) gives us the tendencies for _potential_ outcomes to be drawn on each event. \n",
    "- Likelihoods (the _height_) give us the function to evaluate how probable an _observed_ outcome (or data point) is under a given probability model (i.e. the assignment of area to outcomes (discrete) or ranges of outcomes (continuous)).\n",
    "\n",
    "It just so happens that in the discrete distribution case,\n",
    "the probability value is equivalent to the likelihood value,\n",
    "but as you saw above, with continuous distributions,\n",
    "the likelihood value is some non-zero number at a point,\n",
    "even though the probability of that value (area at that point) is zero.\n",
    "\n",
    "With continuous distributions, the same rules apply.\n",
    "We take the likelihood (given by the probability density function)\n",
    "of each data point and multiply them together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood is all you need\n",
    "\n",
    "Well, strictly speaking, likelihood is _basically most of what we need_.\n",
    "Remember: likelihood is calculated\n",
    "when we evaluate how likely data, assumed to be drawn from a distribution,\n",
    "were drawn from that distribution.\n",
    "\n",
    "For two independently drawn outcomes,\n",
    "we can multiply their likelihoods together\n",
    "to obtain their joint likelihood.\n",
    "This trivially extends to three or more outcomes.\n",
    "\n",
    "There is a principle in statistics, called the [\"Likelihood principle\"][likelihood].\n",
    "You don't have to remember the term, but it is helpful to remember the idea.\n",
    "From Wikipedia:\n",
    "\n",
    "> In statistics, the likelihood principle is the proposition that, given a statistical model, \n",
    "> all the evidence in a sample relevant to model parameters is contained in the likelihood function.\n",
    "\n",
    "[likelihood]: https://en.wikipedia.org/wiki/Likelihood_principle\n",
    "\n",
    "As such, you'll see that in this suite of notebooks,\n",
    "we will be looking _primarily_ at likelihoods, and not probability.\n",
    "After all, the most common thing that we're trying to do\n",
    "is evaluate data against a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Distributions\n",
    "\n",
    "With these components:\n",
    "\n",
    "- spaces of possible outcomes (i.e. the \"_support_\"),\n",
    "- probability mass or density assigned to each outcome,\n",
    "- total probability assigned across all outcomes summing to 1, and\n",
    "- non-deterministic drawing of outcomes per event,\n",
    "\n",
    "we have enough to define a probability distribution.\n",
    "\n",
    "The PMF/PDF can be mathematically or empirically defined,\n",
    "it doesn't really matter,\n",
    "as long as the total area is 1.\n",
    "\n",
    "I think we have enough to define a probability distribution in an understandable fashion for programmers:\n",
    "\n",
    "> A probability distribution is a description of how probability mass or density is assigned to valid outcomes (the support of the distribution), such that the sum of masses or integral of densities equals to 1.\n",
    "\n",
    "That _description_ is most commonly done by a math equation. \n",
    "\n",
    "When we draw data from a probability distribution's space of outcomes, the \"probability\" of each outcome is defined by the probability mass/density function.\n",
    "\n",
    "When we evaluate data against a probability distribution's PMF/PDF, we are evaluating the _likelihood_ of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Variables\n",
    "\n",
    "\"Random variable\" is probably another term that you've seen floating around.\n",
    "\n",
    "As usual, I think contrasts will be the most illuminating here.\n",
    "\n",
    "When we build a model of the world, we'll usually assign _variables_ to represent things.\n",
    "When we so-called \"run the model\" once, usually we'll assign a real value to those variables,\n",
    "yielding one \"realization\" of the model.\n",
    "Now, those variables can be _deterministic_/_fixed_ or _random_/_stochastic_.\n",
    "If over each realization, we \"fix\" the variable at a given value, then it is a _deterministic_ variable.\n",
    "If over each realization, we allow it to vary stochastically, then it is a _random_ variable.\n",
    "\n",
    "Let's move on to a bit of verbiate. \n",
    "When setting up a problem, we'll usually say something like:\n",
    "\n",
    "> Let $p$ be the __random variable__ that models _the probability of heads_, and let $p$ be __Beta distributed__, with parameters $\\alpha$ and $\\beta$\n",
    ">\n",
    "> Let $c$ be the __random variable__ that models the _outcome of a coin flip_, and let $c$ be __Bernoulli distributed__, with parameter $p$.\n",
    "\n",
    "More generically:\n",
    "\n",
    "> Let `symbol` be the random variable that models `thing`, and let `symbol` be distributed by `some distribution`, with parameters `some distribution's parameters`.\n",
    "\n",
    "I think with this in place, we have a sufficiently precise language going forward!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating Probability with Python\n",
    "\n",
    "We've gone through a lot without doing any programming,\n",
    "and the intent here is to ensure that we have a well-defined suite of terms\n",
    "that make clear what we're trying to communicate.\n",
    "Well, congratualtions for staying the course, as in this section, we'll finally get to programming!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating Distribution Objects\n",
    "\n",
    "As an anchoring example, let's use Bernoulli distributions, used to model coin flips.\n",
    "\n",
    "Let $C$ be the random variable that models our coin flips.\n",
    "$C$ is Bernoulli-distributed. Therefore:\n",
    "\n",
    "$$C \\sim Bernoulli(0.5)$$\n",
    "\n",
    "Let's translate that to code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = stats.bernoulli(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating realizations of data\n",
    "\n",
    "We can draw numbers from the Bernoulli, thereby simulating the generation of Bernoulli-distributed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw 10 simulated outcomes from 10 simulated events.\n",
    "c.rvs(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the likelihood of data\n",
    "\n",
    "For this distribution, \n",
    "the likelihood of getting a 1 is equal to the likelihood of getting a 0,\n",
    "which is $0.5$.\n",
    "This can be written using:\n",
    "\n",
    "$$\\mathcal{L}(C=1) = 0.5$$\n",
    "\n",
    "We evaluate this by invoking the PMF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the likelihood of drawing a \"1\"\n",
    "c.pmf(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same goes for the likelihood of drawing a 0:\n",
    "\n",
    "$$\\mathcal{L}(C=0) = 0.5$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the likelihood of drawing a \"0\"\n",
    "c.pmf(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating joint likelihood of independent outcomes\n",
    "\n",
    "The joint likelihood of a head and a tail (1 and 0) is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the joint likelihood of a \"1\" followed by a \"0\"\n",
    "import numpy as np\n",
    "np.product(c.pmf([1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the joint likelihood of three heads is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the joint likelihood of the sequence of results, \"1, 1, 1\".\n",
    "np.product(c.pmf([1, 1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the PMF and distribution of outcomes\n",
    "\n",
    "Visualization helps with learning, so let's do that too.\n",
    "\n",
    "Firstly, we're going to visualize the PMF of the Bernoulli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "xs = np.array([0, 1])\n",
    "ys = c.pmf(xs)\n",
    "width = 0.99\n",
    "ax.bar(xs + width / 2, ys, width=width)\n",
    "ax.set_xlabel(\"Support\")\n",
    "ax.set_xticks([0, 1, 2])\n",
    "ax.set_ylabel(\"PMF\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to visualize the distribution of 10 values drawn from the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "outcomes = c.rvs(10)\n",
    "counts = pd.Series(Counter(outcomes), name=\"biased_outcomes\")\n",
    "counts.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Let's embark on a series of exercises to reinforce some of the points above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Instantiate a model for a biased coin\n",
    "\n",
    "Pick a value `p`, and use it to instantiate a Bernoulli distribution for a biased coin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "bc = stats.bernoulli(p=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Simulated data from the biased coin\n",
    "\n",
    "Now simulate 7 draws from the biased coin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draws = bc.rvs(7)\n",
    "draws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Evaluate joint likelihood of data\n",
    "\n",
    "Now, using the biased coin, evaluate the joint likelihood of the coin flip results `[1, 1, 1, 1, 0, 0, 1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 1, 1, 1, 0, 0, 1]\n",
    "np.product(bc.pmf(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Create a new distribution that better explains the data\n",
    "\n",
    "Now, try creating a new distribution that better explains the data you saw above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bc = stats.bernoulli(p=5/7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Evaluate joint likelihood of data under new distribution\n",
    "\n",
    "Using the same data as above, evaluate the joint likelihood under the new hypothesized distribution that you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.product(new_bc.pmf(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Which better explains the data?\n",
    "\n",
    "Compare the two joint likelihoods. Which better explains the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes' Rule\n",
    "\n",
    "Prior to reading this notebook, you may have seen Bayes' rule.\n",
    "It's so famous, [it's even become a neon sign][bayesjpg]!\n",
    "\n",
    "[bayesjpg]: https://en.wikipedia.org/wiki/File:Bayes%27_Theorem_MMB_01.jpg\n",
    "\n",
    "Bayes' rule looks like this:\n",
    "\n",
    "$$P(A|B) = \n",
    "\\frac{P(B|A)P(A)}\n",
    "{P(B)}\n",
    "$$\n",
    "\n",
    "It is a natural result that comes straight from the rules of probability,\n",
    "being that the joint distribution of two random variables\n",
    "can be written in two equivalent ways:\n",
    "\n",
    "$$P(A, B) = P(A|B)P(B) = P(B|A)P(A)$$\n",
    "\n",
    "Now, I have encountered in many books write,\n",
    "regarding the application of Bayes' rule to statistical modelling,\n",
    "something along the lines of the following:\n",
    "\n",
    "> Now, there is an alternative _interpretation_ of Bayes' rule,\n",
    "> one that replaces the symbol \"A\" with \"Hypothesis\",\n",
    "> and \"B\" with the \"Data\", such that we get:\n",
    "> \n",
    "> $$P(H|D) = \\frac{P(D|H)P(H)}{P(D)}$$\n",
    "\n",
    "At first glance, nothing seems wrong about this statement,\n",
    "but I did remember having a lingering nagging feeling\n",
    "that there was a logical jump unexplained here.\n",
    "\n",
    "More specifically, _why are we allowed to take this interpretation?_\n",
    "\n",
    "It took asking the question to a mathematician friend, Colin Carroll,\n",
    "to finally \"grok\" the idea.\n",
    "Let me try to explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spaces of models and data\n",
    "\n",
    "We have to think back to the fundamental idea of possible spaces.\n",
    "\n",
    "If we set up a Bernoulli probability distribution with parameter $p$,\n",
    "then the space of possible probability distributions that we could instantiate is infinite!\n",
    "This result should not surprise you: $p$ can take on any one of an infinite set of values between 0 and 1, each one giving a different instantiated Bernoulli.\n",
    "As such, a `Bernoulli(p)` hypothesis is drawn from a (very large) space of possible `Bernoulli(p)`s,\n",
    "or more abstractly, hypotheses, thereby giving us a $P(H)$.\n",
    "\n",
    "Moreover, consider our data.\n",
    "The Bernoulli data that came to us, which for example might be `0, 1, 1, 1, 0`,\n",
    "were drawn from a near-infinite space of possible configurations of data.\n",
    "First off, there's no reason why we always have to have three 1s and two 0s in five draws;\n",
    "it could have been five 1s or five 0s.\n",
    "Secondly, the order of data (though it doesn't really matter in this case)\n",
    "for three 1s and two 0s might well have been different.\n",
    "As such, we have the $P(D)$ interpretation.\n",
    "\n",
    "As a modelling decision, we _choose_ to say\n",
    "that our data and model are jointly distributed\n",
    "out of their joint space,\n",
    "thus we have the _joint distribution_\n",
    "between model and data, $P(H, D)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Enough has been written in this notebook.\n",
    "What's much more exciting than learning about definitions\n",
    "is learning how to use probability distributions\n",
    "to simulate how our data were generated!\n",
    "\n",
    "Let's go on to see this in action."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian-modelling-tutorial",
   "language": "python",
   "name": "bayesian-modelling-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
